
# Do not directly collect fluentd's own logs to avoid infinite loops.
<match fluentd.**>
  type null
</match>

# Example:
# {"log":"[info:2016-02-16T16:04:05.930-08:00] Some log text here\n","stream":"stdout","time":"2016-02-17T00:04:05.931087621Z"}
<source>
  type tail
  path /var/log/containers/*.log
  exclude_path /var/log/containers/fluentd-elasticsearch*.log
  pos_file /var/log/es-containers.log.pos
  time_format %Y-%m-%dT%H:%M:%S.%N%Z
  tag kubernetes.*
  format  json
  time_key key3
  read_from_head true
  enable_watch_timer true
#  refresh_interval 5
  read_lines_limit 200
  rotate_wait 5
</source>


<filter kubernetes.**>
  type kubernetes_metadata
</filter>

<match **>
@type elasticsearch
  log_level info
  include_tag_key true
  host 172.25.3.194
  port 9200
  logstash_format true
#  buffer_type file
#  buffer_path /var/log/fluentd.buffer.file
  flush_interval 10
  # The number of threads to flush the buffer.
  num_threads 4
  # The interval between data flushes for queued chunk.
  queued_chunk_flush_interval 1
  retry_limit 17
  disable_retry_limit false
  retry_wait 1.0
  # Never wait longer than 5 minutes between retries.
  #max_retry_wait 
  # Set the chunk limit the same as for fluentd-gcp.
  buffer_chunk_limit 4M
  # Cap buffer memory usage to 2MiB/chunk * 512 chunks = 1024 MiB
  buffer_queue_limit 256
  # HTTP request timeout
  flush_at_shutdown true
  request_timeout 60
  reload_connections false
  reload_on_failure true
</match>
